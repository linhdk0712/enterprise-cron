# H·ªá Th·ªëng Cron Doanh Nghi·ªáp Vi·ªát Nam

N·ªÅn t·∫£ng l·∫≠p l·ªãch v√† th·ª±c thi c√¥ng vi·ªác ph√¢n t√°n, s·∫µn s√†ng cho m√¥i tr∆∞·ªùng production, ƒë∆∞·ª£c x√¢y d·ª±ng b·∫±ng Rust ƒë·ªÉ thay th·∫ø c√°c tri·ªÉn khai Java Quartz + Spring Batch trong c√°c doanh nghi·ªáp Vi·ªát Nam (ng√¢n h√†ng, vi·ªÖn th√¥ng, th∆∞∆°ng m·∫°i ƒëi·ªán t·ª≠).

## üåü T√≠nh NƒÉng Ch√≠nh

### L·∫≠p L·ªãch Linh Ho·∫°t
- **Cron Expression**: H·ªó tr·ª£ c√∫ ph√°p Quartz v·ªõi ƒë·ªô ch√≠nh x√°c ƒë·∫øn gi√¢y
- **Fixed Delay**: L·∫≠p l·ªãch sau khi c√¥ng vi·ªác tr∆∞·ªõc ho√†n th√†nh
- **Fixed Rate**: L·∫≠p l·ªãch theo kho·∫£ng th·ªùi gian c·ªë ƒë·ªãnh
- **One-Time**: Th·ª±c thi m·ªôt l·∫ßn t·∫°i th·ªùi ƒëi·ªÉm c·ª• th·ªÉ
- **Timezone**: H·ªó tr·ª£ m√∫i gi·ªù (m·∫∑c ƒë·ªãnh: Asia/Ho_Chi_Minh)

### C√°c Lo·∫°i C√¥ng Vi·ªác
- **HTTP Request**: GET, POST, PUT v·ªõi x√°c th·ª±c Basic/Bearer/OAuth2
- **Database Query**: PostgreSQL, MySQL, Oracle 19c - th·ª±c thi SQL queries v√† stored procedures
- **File Processing**: ƒê·ªçc/ghi Excel (XLSX), CSV v·ªõi chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu, h·ªó tr·ª£ streaming cho file l·ªõn
- **SFTP**: T·∫£i l√™n/xu·ªëng file qua SSH v·ªõi x√°c th·ª±c password/key, h·ªó tr·ª£ wildcard patterns v√† recursive download

### C√¥ng Vi·ªác ƒêa B∆∞·ªõc (Multi-Step Jobs)
- **ƒê·ªãnh nghƒ©a JSON**: C√¥ng vi·ªác ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a d∆∞·ªõi d·∫°ng JSON documents v·ªõi nhi·ªÅu b∆∞·ªõc tu·∫ßn t·ª±
- **Job Context**: M·ªói execution c√≥ Job Context ri√™ng l∆∞u trong MinIO ƒë·ªÉ truy·ªÅn d·ªØ li·ªáu gi·ªØa c√°c b∆∞·ªõc
- **Step Output References**: Tham chi·∫øu ƒë·∫ßu ra c·ªßa b∆∞·ªõc tr∆∞·ªõc: `{{steps.step1.response.data.id}}`
- **JSONPath Support**: Truy c·∫≠p nested data: `{{steps.step1.output.rows[0].customer_id}}`
- **MinIO Storage**: Job definitions v√† execution context ƒë∆∞·ª£c l∆∞u trong MinIO object storage
- **Sequential Execution**: C√°c b∆∞·ªõc ƒë∆∞·ª£c th·ª±c thi tu·∫ßn t·ª±, m·ªói b∆∞·ªõc c√≥ th·ªÉ s·ª≠ d·ª•ng output c·ªßa b∆∞·ªõc tr∆∞·ªõc

### Ph∆∞∆°ng Th·ª©c K√≠ch Ho·∫°t
- **Scheduled**: T·ª± ƒë·ªông theo l·ªãch c·∫•u h√¨nh (cron, fixed rate, fixed delay, one-time)
- **Manual**: K√≠ch ho·∫°t th·ªß c√¥ng qua dashboard ho·∫∑c API b·ªüi authorized users
- **Webhook**: K√≠ch ho·∫°t t·ª´ h·ªá th·ªëng b√™n ngo√†i qua HTTP POST v·ªõi HMAC-SHA256 signature validation
  - Unique webhook URL cho m·ªói job
  - Rate limiting (configurable per job)
  - Webhook payload/headers/params ƒë∆∞·ª£c l∆∞u trong Job Context
  - Truy c·∫≠p webhook data: `{{webhook.payload.field}}`

### ƒê·ªô Tin C·∫≠y Cao
- **Exactly-Once Execution**: ƒê·∫£m b·∫£o kh√¥ng tr√πng l·∫∑p v·ªõi Redis RedLock v√† idempotency keys
- **Retry Strategy**: Exponential backoff v·ªõi jitter (t·ªëi ƒëa 10 l·∫ßn)
- **Circuit Breaker**: Fail-fast khi h·ªá th·ªëng ngo√†i kh√¥ng kh·∫£ d·ª•ng
- **Dead Letter Queue**: L∆∞u tr·ªØ c√¥ng vi·ªác th·∫•t b·∫°i sau khi h·∫øt retry
- **Graceful Shutdown**: Ho√†n th√†nh c√¥ng vi·ªác ƒëang ch·∫°y tr∆∞·ªõc khi t·∫Øt

### Qu·∫£n L√Ω Bi·∫øn (Variables)
- **Global Variables**: Kh·∫£ d·ª•ng cho t·∫•t c·∫£ c√¥ng vi·ªác
- **Job-Specific Variables**: Ch·ªâ kh·∫£ d·ª•ng cho c√¥ng vi·ªác c·ª• th·ªÉ
- **Template Substitution**: `${VAR_NAME}` trong URL, headers, body, SQL
- **Encryption**: M√£ h√≥a bi·∫øn nh·∫°y c·∫£m (passwords, API keys)
- **Masking**: Che gi·∫•u gi√° tr·ªã nh·∫°y c·∫£m trong dashboard

### Dashboard Th·ªùi Gian Th·ª±c
- **HTMX**: C·∫≠p nh·∫≠t ƒë·ªông kh√¥ng c·∫ßn reload trang
- **Server-Sent Events**: Push c·∫≠p nh·∫≠t tr·∫°ng th√°i real-time
- **Responsive**: T·ªëi ∆∞u cho mobile v√† desktop
- **Visual Job Builder**: T·∫°o c√¥ng vi·ªác qua giao di·ªán form
- **Import/Export**: Sao l∆∞u v√† chia s·∫ª ƒë·ªãnh nghƒ©a c√¥ng vi·ªác d∆∞·ªõi d·∫°ng JSON
  - Export jobs v·ªõi sensitive data masking
  - Import jobs v·ªõi JSON schema validation
  - Bulk export/import support
  - Export metadata (date, user, version) cho traceability

### X√°c Th·ª±c Linh Ho·∫°t
- **Database Mode**: Qu·∫£n l√Ω user trong PostgreSQL v·ªõi bcrypt
- **Keycloak Mode**: T√≠ch h·ª£p v·ªõi Keycloak identity provider
- **RBAC**: Ki·ªÉm so√°t truy c·∫≠p d·ª±a tr√™n vai tr√≤
- **JWT Tokens**: X√°c th·ª±c API v·ªõi JSON Web Tokens
- **Audit Logging**: Ghi log t·∫•t c·∫£ thao t√°c v·ªõi user identity

### Observability To√†n Di·ªán
- **Structured Logging**: JSON logs v·ªõi trace context
- **Prometheus Metrics**: Counters, histograms, gauges
- **OpenTelemetry Tracing**: Distributed tracing v·ªõi OTLP
- **Alerting**: C·∫£nh b√°o t·ª± ƒë·ªông sau 3 l·∫ßn th·∫•t b·∫°i li√™n ti·∫øp

## üìã Y√™u C·∫ßu H·ªá Th·ªëng

### Ph·∫ßn M·ªÅm
- **Rust**: 1.75+ (2021 Edition)
- **PostgreSQL**: 14+ (System Database - l∆∞u job metadata v√† execution history)
- **Redis**: 7.0+ (Distributed Locking v√† Rate Limiting)
- **NATS**: 2.10+ (Job Queue v·ªõi JetStream)
- **MinIO**: RELEASE.2024-01+ (Object Storage - l∆∞u job definitions, execution context, v√† files)

### Ph·∫ßn C·ª©ng (Khuy·∫øn Ngh·ªã)
- **CPU**: 4 cores
- **RAM**: 8GB
- **Disk**: 50GB SSD
- **Network**: 1Gbps

## üöÄ C√†i ƒê·∫∑t Nhanh

### 1. Clone Repository

```bash
git clone https://github.com/vietnam-enterprise/cron-system.git
cd cron-system
```

### 2. C√†i ƒê·∫∑t Dependencies

```bash
# C√†i ƒë·∫∑t Rust
curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

# C√†i ƒë·∫∑t sqlx-cli
cargo install sqlx-cli --no-default-features --features postgres
```

### 3. Kh·ªüi ƒê·ªông Services v·ªõi Docker Compose

```bash
# Build Docker image
docker build -t vietnam-cron:latest .

# Kh·ªüi ƒë·ªông t·∫•t c·∫£ services
docker-compose up -d

# Ki·ªÉm tra tr·∫°ng th√°i
docker-compose ps

# Xem logs
docker-compose logs -f api
```

### 4. Ch·∫°y Database Migrations

```bash
# Set database URL
export DATABASE_URL="postgresql://cronuser:cronpass@localhost:5432/vietnam_cron"

# Ch·∫°y migrations
sqlx migrate run
```

### 5. C·∫•u H√¨nh MinIO

MinIO ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ l∆∞u tr·ªØ job definitions, execution context, v√† files.

```bash
# MinIO ƒë√£ ƒë∆∞·ª£c kh·ªüi ƒë·ªông qua docker-compose
# Truy c·∫≠p MinIO Console: http://localhost:9001
# Username: minioadmin
# Password: minioadmin

# T·∫°o bucket (t·ª± ƒë·ªông t·∫°o khi kh·ªüi ƒë·ªông)
# Bucket name: vietnam-cron

# C·∫•u tr√∫c th∆∞ m·ª•c trong MinIO:
# jobs/{job_id}/definition.json                          - Job definition
# jobs/{job_id}/executions/{execution_id}/context.json   - Job Context
# jobs/{job_id}/executions/{execution_id}/output/        - Output files
# jobs/{job_id}/executions/{execution_id}/sftp/          - SFTP downloads
```

### 6. Truy C·∫≠p Dashboard

M·ªü tr√¨nh duy·ªát v√† truy c·∫≠p: **http://localhost:8080**

ƒêƒÉng nh·∫≠p v·ªõi t√†i kho·∫£n m·∫∑c ƒë·ªãnh (database mode):
- Username: `admin`
- Password: `admin123`

## üèóÔ∏è Ki·∫øn Tr√∫c H·ªá Th·ªëng

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         Load Balancer                            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ                         ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ  API Server 1  ‚îÇ       ‚îÇ  API Server N  ‚îÇ
        ‚îÇ  (Axum + HTMX) ‚îÇ       ‚îÇ  (Axum + HTMX) ‚îÇ
        ‚îÇ  + Webhooks    ‚îÇ       ‚îÇ  + Webhooks    ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                ‚îÇ                         ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                    ‚îÇ                    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Scheduler 1   ‚îÇ  ‚îÇ  Scheduler N    ‚îÇ  ‚îÇ   Worker 1-N   ‚îÇ
‚îÇ  (Distributed  ‚îÇ  ‚îÇ  (Distributed   ‚îÇ  ‚îÇ  (Multi-Step   ‚îÇ
‚îÇ   Locking)     ‚îÇ  ‚îÇ   Locking)      ‚îÇ  ‚îÇ   Execution)   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ                    ‚îÇ                    ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                             ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ                    ‚îÇ                    ‚îÇ            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ   PostgreSQL   ‚îÇ  ‚îÇ     Redis       ‚îÇ  ‚îÇ NATS JetStream ‚îÇ ‚îÇ
‚îÇ  (Metadata)    ‚îÇ  ‚îÇ  (Dist Lock +   ‚îÇ  ‚îÇ  (Job Queue)   ‚îÇ ‚îÇ
‚îÇ                ‚îÇ  ‚îÇ   Rate Limit)   ‚îÇ  ‚îÇ                ‚îÇ ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
                                                             ‚îÇ
                                                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                                                    ‚îÇ     MinIO       ‚îÇ
                                                    ‚îÇ  (Job Defs +    ‚îÇ
                                                    ‚îÇ   Context +     ‚îÇ
                                                    ‚îÇ   Files)        ‚îÇ
                                                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### C√°c Th√†nh Ph·∫ßn

1. **Scheduler**: Ph√°t hi·ªán c√¥ng vi·ªác ƒë·∫øn h·∫°n v√† ƒë·∫©y v√†o queue
2. **Worker**: Ti√™u th·ª• c√¥ng vi·ªác t·ª´ queue v√† th·ª±c thi
3. **API Server**: REST API, dashboard HTMX, v√† webhook handler
4. **PostgreSQL**: L∆∞u tr·ªØ metadata c√¥ng vi·ªác v√† l·ªãch s·ª≠ th·ª±c thi
5. **Redis**: Distributed locking v√† rate limiting
6. **NATS JetStream**: Job queue v·ªõi exactly-once delivery
7. **MinIO**: L∆∞u tr·ªØ job definitions, execution context, v√† files

## ‚öôÔ∏è C·∫•u H√¨nh

### C·∫•u H√¨nh Ph√¢n L·ªõp

H·ªá th·ªëng s·ª≠ d·ª•ng c·∫•u h√¨nh ph√¢n l·ªõp v·ªõi th·ª© t·ª± ∆∞u ti√™n:

1. **Default values** (trong binary)
2. **Config file** (`config/default.toml`)
3. **Local config** (`config/local.toml` - kh√¥ng commit)
4. **Environment variables** (prefix `APP__`)
5. **Command-line arguments** (∆∞u ti√™n cao nh·∫•t)

### File C·∫•u H√¨nh M·∫´u

T·∫°o file `config/local.toml`:

```toml
[server]
host = "0.0.0.0"
port = 8080

[database]
url = "postgresql://cronuser:cronpass@localhost:5432/vietnam_cron"
max_connections = 20
min_connections = 5

[redis]
url = "redis://:redispass@localhost:6379"
pool_size = 10

[nats]
url = "nats://localhost:4222"
stream_name = "job_stream"

[minio]
endpoint = "localhost:9000"
access_key = "minioadmin"
secret_key = "minioadmin"
bucket = "vietnam-cron"
region = "us-east-1"

[auth]
mode = "database"  # Ho·∫∑c "keycloak"
jwt_secret = "your-secret-key-here"
jwt_expiration_hours = 24

# C·∫•u h√¨nh Keycloak (ch·ªâ c·∫ßn n·∫øu mode = "keycloak")
[auth.keycloak]
server_url = "https://keycloak.example.com"
realm = "vietnam-cron"
client_id = "cron-client"

[scheduler]
poll_interval_seconds = 10
lock_ttl_seconds = 30

[worker]
concurrency = 10
max_retries = 10
timeout_seconds = 300

[observability]
log_level = "info"
metrics_port = 9090
tracing_endpoint = "http://localhost:4317"
```

### Bi·∫øn M√¥i Tr∆∞·ªùng

```bash
# Database
export APP__DATABASE__URL="postgresql://user:pass@localhost/vietnam_cron"
export APP__DATABASE__MAX_CONNECTIONS=20

# Redis
export APP__REDIS__URL="redis://:password@localhost:6379"

# NATS
export APP__NATS__URL="nats://localhost:4222"

# MinIO
export APP__MINIO__ENDPOINT="localhost:9000"
export APP__MINIO__ACCESS_KEY="minioadmin"
export APP__MINIO__SECRET_KEY="minioadmin"

# Authentication
export APP__AUTH__MODE="database"
export APP__AUTH__JWT_SECRET="your-secret-key"

# Observability
export APP__OBSERVABILITY__LOG_LEVEL="info"
```

## üî® Build v√† Development

### Build t·ª´ Source

```bash
# Build t·∫•t c·∫£ binaries
cargo build --release

# Build binary c·ª• th·ªÉ
cargo build --release --bin scheduler
cargo build --release --bin worker
cargo build --release --bin api

# Binaries s·∫Ω ·ªü trong target/release/
```

### Ch·∫°y Development Mode

```bash
# Terminal 1: Scheduler
cargo run --bin scheduler

# Terminal 2: Worker
cargo run --bin worker

# Terminal 3: API Server
cargo run --bin api
```

### Ch·∫°y Tests

```bash
# T·∫•t c·∫£ tests
cargo test --workspace

# Unit tests
cargo test --lib

# Property-based tests
cargo test property_

# Integration tests
cargo test --test '*_integration'
```

## üì¶ Tri·ªÉn Khai

### Docker Compose (Khuy·∫øn Ngh·ªã cho Development)

```bash
# Kh·ªüi ƒë·ªông t·∫•t c·∫£ services
docker-compose up -d

# Kh·ªüi ƒë·ªông v·ªõi monitoring (Prometheus + Grafana)
docker-compose --profile monitoring up -d

# D·ª´ng services
docker-compose down

# X√≥a volumes (c·∫©n th·∫≠n: m·∫•t d·ªØ li·ªáu!)
docker-compose down -v
```

### Kubernetes v·ªõi Helm (Production)

```bash
# C√†i ƒë·∫∑t v·ªõi values m·∫∑c ƒë·ªãnh
helm install my-cron ./charts/vietnam-enterprise-cron \
  --namespace cron-system \
  --create-namespace

# C√†i ƒë·∫∑t v·ªõi custom values
helm install my-cron ./charts/vietnam-enterprise-cron \
  -f custom-values.yaml \
  --namespace cron-system \
  --create-namespace

# Upgrade
helm upgrade my-cron ./charts/vietnam-enterprise-cron \
  -f custom-values.yaml

# Uninstall
helm uninstall my-cron --namespace cron-system
```

Xem chi ti·∫øt trong [DEPLOYMENT.md](DEPLOYMENT.md)

## üìñ S·ª≠ D·ª•ng

### T√≠nh NƒÉng File Processing

H·ªá th·ªëng h·ªó tr·ª£ x·ª≠ l√Ω file Excel (XLSX) v√† CSV v·ªõi c√°c kh·∫£ nƒÉng:

#### ƒê·ªçc File Excel
- ƒê·ªçc t·∫•t c·∫£ sheets ho·∫∑c ch·ªçn sheet c·ª• th·ªÉ (by name ho·∫∑c index)
- Parse data th√†nh structured JSON
- H·ªó tr·ª£ streaming cho file l·ªõn (>100MB)
- L∆∞u tr·ªØ file trong MinIO

#### ƒê·ªçc File CSV
- Configurable delimiter (comma, semicolon, tab)
- Parse rows th√†nh structured JSON
- H·ªó tr·ª£ streaming cho file l·ªõn

#### Data Transformations
- **Column Mapping**: ƒê·ªïi t√™n c·ªôt (e.g., "Product ID" ‚Üí "product_id")
- **Type Conversion**: Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu (string ‚Üí integer, decimal)
- **Filtering**: L·ªçc rows theo ƒëi·ªÅu ki·ªán (e.g., "amount > 0")

#### Ghi File
- Ghi Excel (XLSX) t·ª´ JSON data
- Ghi CSV t·ª´ JSON data
- L∆∞u output files trong MinIO v·ªõi path format: `jobs/{job_id}/executions/{execution_id}/output/{filename}`

### T√≠nh NƒÉng SFTP Operations

H·ªá th·ªëng h·ªó tr·ª£ k·∫øt n·ªëi SFTP servers ƒë·ªÉ t·∫£i l√™n/xu·ªëng files:

#### SFTP Download
- Download single file ho·∫∑c multiple files v·ªõi wildcard patterns (e.g., `*.csv`, `TXN_*.xlsx`)
- Recursive directory download
- L∆∞u downloaded files trong MinIO: `jobs/{job_id}/executions/{execution_id}/sftp/downloads/{filename}`
- Store file metadata (filename, size, download_time) trong Job Context

#### SFTP Upload
- Upload files t·ª´ MinIO l√™n SFTP server
- T·ª± ƒë·ªông t·∫°o remote directories n·∫øu ch∆∞a t·ªìn t·∫°i
- Store upload metadata trong Job Context

#### SFTP Authentication
- **Password Authentication**: Username + password
- **SSH Key Authentication**: Username + private key file
- Host key verification ƒë·ªÉ prevent MITM attacks

#### SFTP Features
- Streaming transfer cho large files (>100MB)
- Retry v·ªõi exponential backoff cho connection errors
- Fail immediately cho authentication/file not found errors
- Reference files t·ª´ previous steps: `{{steps.step1.output.files[0].path}}`

### T·∫°o C√¥ng Vi·ªác HTTP

```json
{
  "name": "Fetch User Data",
  "description": "L·∫•y d·ªØ li·ªáu user t·ª´ API",
  "schedule": {
    "type": "cron",
    "expression": "0 0 * * * *",
    "timezone": "Asia/Ho_Chi_Minh"
  },
  "steps": [
    {
      "id": "fetch_users",
      "name": "Fetch Users",
      "type": "http",
      "config": {
        "method": "GET",
        "url": "https://api.example.com/users",
        "headers": {
          "Authorization": "Bearer ${API_TOKEN}"
        }
      }
    }
  ],
  "timeout_seconds": 300,
  "max_retries": 3
}
```

### T·∫°o C√¥ng Vi·ªác Database

```json
{
  "name": "Daily Report",
  "description": "T·∫°o b√°o c√°o h√†ng ng√†y",
  "schedule": {
    "type": "cron",
    "expression": "0 0 6 * * *",
    "timezone": "Asia/Ho_Chi_Minh"
  },
  "steps": [
    {
      "id": "generate_report",
      "name": "Generate Report",
      "type": "database",
      "config": {
        "database_type": "postgresql",
        "connection_string": "${DB_CONNECTION_STRING}",
        "query": "SELECT * FROM orders WHERE created_at >= CURRENT_DATE - INTERVAL '1 day'"
      }
    }
  ]
}
```

### T·∫°o C√¥ng Vi·ªác ƒêa B∆∞·ªõc

```json
{
  "name": "Process Orders",
  "description": "L·∫•y orders t·ª´ API v√† l∆∞u v√†o database",
  "schedule": {
    "type": "fixed_rate",
    "interval_seconds": 300
  },
  "steps": [
    {
      "id": "fetch_orders",
      "name": "Fetch Orders from API",
      "type": "http",
      "config": {
        "method": "GET",
        "url": "https://api.example.com/orders"
      }
    },
    {
      "id": "save_orders",
      "name": "Save to Database",
      "type": "database",
      "config": {
        "database_type": "postgresql",
        "connection_string": "${DB_CONNECTION_STRING}",
        "query": "INSERT INTO orders (data) VALUES ($1)",
        "parameters": ["{{steps.fetch_orders.response.body}}"]
      }
    }
  ]
}
```

### T·∫°o C√¥ng Vi·ªác File Processing

```json
{
  "name": "Process Daily Sales Report",
  "description": "ƒê·ªçc file Excel, x·ª≠ l√Ω d·ªØ li·ªáu, l∆∞u database",
  "schedule": {
    "type": "cron",
    "expression": "0 30 7 * * *",
    "timezone": "Asia/Ho_Chi_Minh"
  },
  "steps": [
    {
      "id": "read_excel",
      "name": "Read Excel File",
      "type": "file_processing",
      "config": {
        "operation": "read",
        "format": "excel",
        "source_path": "reports/daily_sales.xlsx",
        "options": {
          "sheet_name": "Sales Data",
          "transformations": [
            {
              "type": "column_mapping",
              "from": "Product ID",
              "to": "product_id"
            },
            {
              "type": "type_conversion",
              "column": "quantity",
              "target_type": "integer"
            },
            {
              "type": "filter",
              "condition": "quantity > 0"
            }
          ]
        }
      }
    },
    {
      "id": "save_to_database",
      "name": "Save to Database",
      "type": "database",
      "config": {
        "database_type": "postgresql",
        "connection_string": "${DB_CONNECTION_STRING}",
        "query": "INSERT INTO sales_data (product_id, quantity) SELECT product_id, quantity FROM json_populate_recordset(null::sales_data, $1::json)",
        "parameters": ["{{steps.read_excel.output.data}}"]
      }
    }
  ]
}
```

### T·∫°o C√¥ng Vi·ªác SFTP

```json
{
  "name": "Download Bank Transactions via SFTP",
  "description": "T·∫£i file giao d·ªãch t·ª´ SFTP, x·ª≠ l√Ω v√† l∆∞u database",
  "schedule": {
    "type": "cron",
    "expression": "0 0 1 * * *",
    "timezone": "Asia/Ho_Chi_Minh"
  },
  "steps": [
    {
      "id": "download_files",
      "name": "Download from SFTP",
      "type": "sftp",
      "config": {
        "operation": "download",
        "host": "sftp.bank.example.com",
        "port": 22,
        "auth": {
          "type": "password",
          "username": "${SFTP_USERNAME}",
          "password": "${SFTP_PASSWORD}"
        },
        "remote_path": "/exports/transactions/TXN_*.csv",
        "options": {
          "wildcard_pattern": "TXN_*.csv",
          "verify_host_key": true,
          "streaming": true
        }
      }
    },
    {
      "id": "process_csv",
      "name": "Process CSV Files",
      "type": "file_processing",
      "config": {
        "operation": "read",
        "format": "csv",
        "source_path": "{{steps.download_files.output.files[0].path}}",
        "options": {
          "delimiter": ",",
          "transformations": [
            {
              "type": "column_mapping",
              "from": "Transaction ID",
              "to": "transaction_id"
            },
            {
              "type": "type_conversion",
              "column": "amount",
              "target_type": "decimal"
            }
          ]
        }
      }
    },
    {
      "id": "save_transactions",
      "name": "Save to Database",
      "type": "database",
      "config": {
        "database_type": "postgresql",
        "connection_string": "${DB_CONNECTION_STRING}",
        "query": "INSERT INTO transactions (transaction_id, amount) SELECT transaction_id, amount FROM json_populate_recordset(null::transactions, $1::json)",
        "parameters": ["{{steps.process_csv.output.data}}"]
      }
    }
  ]
}
```

### T·∫°o Webhook Trigger

```json
{
  "name": "Process Webhook",
  "description": "X·ª≠ l√Ω webhook t·ª´ h·ªá th·ªëng b√™n ngo√†i",
  "triggers": {
    "scheduled": false,
    "manual": true,
    "webhook": {
      "enabled": true,
      "rate_limit": {
        "max_requests": 100,
        "window_seconds": 60
      }
    }
  },
  "steps": [
    {
      "id": "process_data",
      "name": "Process Webhook Data",
      "type": "database",
      "config": {
        "database_type": "postgresql",
        "connection_string": "${DB_CONNECTION_STRING}",
        "query": "INSERT INTO webhook_events (user_id, event_type) VALUES ($1, $2)",
        "parameters": [
          "{{webhook.payload.user_id}}",
          "{{webhook.payload.event_type}}"
        ]
      }
    }
  ]
}
```

### Import/Export Jobs

#### Export Job
```bash
# Via API
curl -X POST http://localhost:8080/api/jobs/{job_id}/export \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -o job-export.json

# Via Dashboard
# 1. M·ªü job details page
# 2. Click n√∫t "Export"
# 3. File JSON s·∫Ω ƒë∆∞·ª£c download v·ªõi format: job-{name}-{timestamp}.json
# 4. Sensitive data (passwords, API keys) ƒë∆∞·ª£c mask v·ªõi placeholders
```

#### Import Job
```bash
# Via API
curl -X POST http://localhost:8080/api/jobs/import \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d @job-definition.json

# Via Dashboard
# 1. Click n√∫t "Import Job"
# 2. Upload JSON file
# 3. Nh·∫≠p values cho sensitive data placeholders
# 4. Click "Import"
# 5. Job m·ªõi ƒë∆∞·ª£c t·∫°o v·ªõi job_id m·ªõi
```

#### Bulk Export/Import
```bash
# Bulk Export
curl -X POST http://localhost:8080/api/jobs/export/bulk \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"job_ids": ["id1", "id2", "id3"]}' \
  -o jobs-export.zip

# Bulk Import
curl -X POST http://localhost:8080/api/jobs/import/bulk \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -F "file=@jobs-export.zip"
```

### S·ª≠ D·ª•ng Webhooks

#### C·∫•u H√¨nh Webhook cho Job

```json
{
  "name": "Payment Notification Handler",
  "triggers": {
    "scheduled": false,
    "manual": true,
    "webhook": {
      "enabled": true,
      "secret_key": "your-webhook-secret-key",
      "rate_limit": {
        "max_requests": 100,
        "window_seconds": 60
      }
    }
  },
  "steps": [...]
}
```

#### Webhook URL Format
```
https://your-domain.com/api/webhooks/{job_id}
```

#### G·ªçi Webhook t·ª´ External System

```bash
# 1. Prepare payload
PAYLOAD='{"transaction_id":"TXN123","amount":1500000,"status":"success"}'

# 2. Generate HMAC-SHA256 signature
SECRET="your-webhook-secret-key"
SIGNATURE=$(echo -n "$PAYLOAD" | openssl dgst -sha256 -hmac "$SECRET" -binary | base64)

# 3. Send webhook request
curl -X POST https://your-domain.com/api/webhooks/{job_id} \
  -H "Content-Type: application/json" \
  -H "X-Webhook-Signature: $SIGNATURE" \
  -d "$PAYLOAD"

# Response: 202 Accepted
# {"execution_id": "uuid", "status": "queued"}
```

#### Truy C·∫≠p Webhook Data trong Job Steps

```json
{
  "steps": [
    {
      "id": "process",
      "type": "database",
      "config": {
        "query": "INSERT INTO payments (txn_id, amount) VALUES ($1, $2)",
        "parameters": [
          "{{webhook.payload.transaction_id}}",
          "{{webhook.payload.amount}}"
        ]
      }
    }
  ]
}
```

#### Webhook Security Features
- **Signature Validation**: HMAC-SHA256 signature trong `X-Webhook-Signature` header
- **Rate Limiting**: Configurable per job (e.g., 100 requests/minute)
- **Job Status Check**: Reject webhooks cho disabled jobs (403 Forbidden)
- **Invalid Signature**: Reject v·ªõi 401 Unauthorized

## üîê B·∫£o M·∫≠t

### Best Practices

1. **Thay ƒë·ªïi m·∫≠t kh·∫©u m·∫∑c ƒë·ªãnh**
   ```bash
   # PostgreSQL
   ALTER USER cronuser WITH PASSWORD 'new-secure-password';
   
   # Redis
   CONFIG SET requirepass "new-secure-password"
   ```

2. **S·ª≠ d·ª•ng JWT secret m·∫°nh**
   ```bash
   # Generate random secret
   openssl rand -base64 32
   ```

3. **M√£ h√≥a bi·∫øn nh·∫°y c·∫£m**
   - ƒê√°nh d·∫•u bi·∫øn l√† `is_sensitive = true`
   - H·ªá th·ªëng t·ª± ƒë·ªông m√£ h√≥a trong database

4. **S·ª≠ d·ª•ng TLS/SSL**
   ```toml
   [database]
   url = "postgresql://user:pass@host/db?sslmode=require"
   
   [minio]
   use_ssl = true
   ```

5. **RBAC Permissions**
   - `job:read` - Xem c√¥ng vi·ªác
   - `job:write` - T·∫°o/s·ª≠a c√¥ng vi·ªác
   - `job:execute` - K√≠ch ho·∫°t th·ªß c√¥ng
   - `job:delete` - X√≥a c√¥ng vi·ªác
   - `execution:read` - Xem l·ªãch s·ª≠ th·ª±c thi

## üìä Monitoring

### Prometheus Metrics

Truy c·∫≠p metrics t·∫°i: **http://localhost:9090/metrics**

C√°c metrics quan tr·ªçng:
- `job_success_total` - T·ªïng s·ªë c√¥ng vi·ªác th√†nh c√¥ng
- `job_failed_total` - T·ªïng s·ªë c√¥ng vi·ªác th·∫•t b·∫°i
- `job_duration_seconds` - Th·ªùi gian th·ª±c thi
- `job_queue_size` - S·ªë l∆∞·ª£ng c√¥ng vi·ªác trong queue
- `scheduler_lock_acquisitions_total` - S·ªë l·∫ßn acquire lock
- `worker_executions_active` - S·ªë c√¥ng vi·ªác ƒëang ch·∫°y

### Grafana Dashboards

N·∫øu ch·∫°y v·ªõi monitoring profile:

```bash
docker-compose --profile monitoring up -d
```

Truy c·∫≠p Grafana: **http://localhost:3000**
- Username: `admin`
- Password: `admin`

### Structured Logs

Logs ƒë∆∞·ª£c xu·∫•t ra d∆∞·ªõi d·∫°ng JSON:

```json
{
  "timestamp": "2025-01-15T10:30:00Z",
  "level": "INFO",
  "message": "Job execution started",
  "job_id": "123e4567-e89b-12d3-a456-426614174000",
  "execution_id": "987fcdeb-51a2-43f7-8765-123456789abc",
  "trace_id": "abc123",
  "span_id": "def456"
}
```

## üêõ Troubleshooting

### C√¥ng Vi·ªác Kh√¥ng Ch·∫°y

```bash
# Ki·ªÉm tra scheduler logs
docker-compose logs scheduler

# Ki·ªÉm tra job c√≥ enabled kh√¥ng
curl http://localhost:8080/api/jobs/{job_id}

# Ki·ªÉm tra distributed lock
redis-cli -a redispass KEYS "lock:*"
```

### Worker Kh√¥ng Ti√™u Th·ª• Jobs

```bash
# Ki·ªÉm tra worker logs
docker-compose logs worker

# Ki·ªÉm tra NATS queue
curl http://localhost:8222/jsz?acc=1&consumers=1

# Ki·ªÉm tra connection
docker-compose exec worker nc -zv nats 4222
```

### Database Connection Issues

```bash
# Test PostgreSQL connection
docker-compose exec postgres psql -U cronuser -d vietnam_cron -c "SELECT 1"

# Ki·ªÉm tra migrations
sqlx migrate info

# Ch·∫°y l·∫°i migrations
sqlx migrate run
```

### MinIO Connection Issues

```bash
# Test MinIO connection
curl http://localhost:9000/minio/health/live

# Ki·ªÉm tra bucket
docker-compose exec minio mc ls local/vietnam-cron

# Xem job definitions
docker-compose exec minio mc ls local/vietnam-cron/jobs/

# Xem execution context
docker-compose exec minio mc ls local/vietnam-cron/jobs/{job_id}/executions/

# Download job definition
docker-compose exec minio mc cp local/vietnam-cron/jobs/{job_id}/definition.json /tmp/

# Download execution context
docker-compose exec minio mc cp local/vietnam-cron/jobs/{job_id}/executions/{execution_id}/context.json /tmp/
```

### File Processing Issues

```bash
# Ki·ªÉm tra file trong MinIO
docker-compose exec minio mc ls local/vietnam-cron/jobs/{job_id}/executions/{execution_id}/

# Download file ƒë·ªÉ debug
docker-compose exec minio mc cp local/vietnam-cron/jobs/{job_id}/executions/{execution_id}/output/file.xlsx /tmp/

# Ki·ªÉm tra worker logs cho file processing errors
docker-compose logs worker | grep "file_processing"

# Common issues:
# - Invalid Excel format: Ensure file is .xlsx (not .xls)
# - CSV delimiter mismatch: Check delimiter config matches file
# - Sheet not found: Verify sheet name exists in Excel file
# - Memory issues: Enable streaming for large files (>100MB)
```

### SFTP Connection Issues

```bash
# Test SFTP connection manually
sftp -P 22 username@sftp.example.com

# Ki·ªÉm tra worker logs cho SFTP errors
docker-compose logs worker | grep "sftp"

# Common issues:
# - Authentication failed: Verify username/password or SSH key
# - Host key verification failed: Add host key to known_hosts or disable verification
# - File not found: Check remote_path and wildcard patterns
# - Permission denied: Verify user has read/write permissions on remote server
# - Connection timeout: Check network connectivity and firewall rules
```

### Webhook Issues

```bash
# Test webhook signature generation
PAYLOAD='{"test":"data"}'
SECRET="your-secret"
SIGNATURE=$(echo -n "$PAYLOAD" | openssl dgst -sha256 -hmac "$SECRET" -binary | base64)
echo "Signature: $SIGNATURE"

# Send test webhook
curl -X POST http://localhost:8080/api/webhooks/{job_id} \
  -H "Content-Type: application/json" \
  -H "X-Webhook-Signature: $SIGNATURE" \
  -d "$PAYLOAD"

# Ki·ªÉm tra webhook logs
docker-compose logs api | grep "webhook"

# Common issues:
# - 401 Unauthorized: Invalid signature - verify secret key matches
# - 403 Forbidden: Job is disabled - enable job first
# - 429 Too Many Requests: Rate limit exceeded - wait or increase limit
# - Job not found: Verify job_id in webhook URL
```

## üìö T√†i Li·ªáu

- [Requirements](.kiro/specs/vietnam-enterprise-cron/requirements.md) - Y√™u c·∫ßu chi ti·∫øt
- [Design](.kiro/specs/vietnam-enterprise-cron/design.md) - Thi·∫øt k·∫ø ki·∫øn tr√∫c
- [Tasks](.kiro/specs/vietnam-enterprise-cron/tasks.md) - K·∫ø ho·∫°ch tri·ªÉn khai
- [Deployment](DEPLOYMENT.md) - H∆∞·ªõng d·∫´n tri·ªÉn khai chi ti·∫øt
- [Migrations](migrations/README.md) - Database migrations
- [Sequence Diagrams](.kiro/specs/vietnam-enterprise-cron/SEQUENCE-DIAGRAMS-README.md) - S∆° ƒë·ªì lu·ªìng

## ü§ù ƒê√≥ng G√≥p

Ch√∫ng t√¥i hoan ngh√™nh m·ªçi ƒë√≥ng g√≥p! Vui l√≤ng:

1. Fork repository
2. T·∫°o feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. M·ªü Pull Request

### Coding Standards

- Tu√¢n th·ªß 100% [RECC 2025 rules](.kiro/steering/implments-rules.md)
- Kh√¥ng d√πng `unwrap()` trong production code
- Vi·∫øt property-based tests (minimum 100 iterations)
- Structured logging v·ªõi `tracing` crate
- Compile-time query checking v·ªõi `sqlx`

## üìÑ License

MIT License - xem file [LICENSE](LICENSE) ƒë·ªÉ bi·∫øt chi ti·∫øt

## üÜò H·ªó Tr·ª£

- **GitHub Issues**: https://github.com/vietnam-enterprise/cron-system/issues
- **Email**: support@vietnam-enterprise.com
- **Documentation**: https://docs.vietnam-enterprise.com/cron-system

## üéØ Roadmap

### Version 1.0 (Current)
- ‚úÖ Distributed job scheduling v·ªõi Redis RedLock
- ‚úÖ Multi-step jobs v·ªõi Job Context trong MinIO
- ‚úÖ HTTP executor v·ªõi Basic/Bearer/OAuth2 auth
- ‚úÖ Database executor (PostgreSQL, MySQL, Oracle 19c)
- ‚úÖ File Processing executor (Excel XLSX, CSV) v·ªõi transformations
- ‚úÖ SFTP executor v·ªõi wildcard patterns v√† streaming
- ‚úÖ Webhook triggers v·ªõi HMAC-SHA256 validation
- ‚úÖ Job Import/Export v·ªõi sensitive data masking
- ‚úÖ HTMX dashboard v·ªõi real-time updates
- ‚úÖ Database v√† Keycloak authentication v·ªõi RBAC
- ‚úÖ Comprehensive observability (Prometheus + OpenTelemetry)
- ‚úÖ Property-based testing v·ªõi 100+ iterations

### Version 1.1 (Planned)
- [ ] GraphQL API
- [ ] Conditional logic trong multi-step jobs (if/else, loops)
- [ ] Job dependencies v√† DAG execution
- [ ] Multi-tenancy support
- [ ] Advanced alerting (Slack, Email, SMS, PagerDuty)
- [ ] Job versioning v√† rollback
- [ ] Advanced file formats (XML, JSON, Parquet)

### Version 2.0 (Future)
- [ ] Visual workflow designer v·ªõi drag-and-drop
- [ ] Machine learning-based job optimization
- [ ] Advanced analytics dashboard v·ªõi predictions
- [ ] Plugin system cho custom executors
- [ ] Distributed tracing visualization
- [ ] Cost optimization recommendations

## üèÜ T·∫°i Sao Ch·ªçn H·ªá Th·ªëng N√†y?

### So V·ªõi Java Quartz + Spring Batch

| T√≠nh NƒÉng | Vietnam Cron (Rust) | Java Quartz + Spring Batch |
|-----------|---------------------|----------------------------|
| **Memory Usage** | ~50MB | ~500MB+ |
| **Startup Time** | <1s | 10-30s |
| **Throughput** | 1000+ jobs/s | 100-200 jobs/s |
| **Type Safety** | Compile-time | Runtime |
| **Exactly-Once** | Built-in | C·∫ßn c·∫•u h√¨nh ph·ª©c t·∫°p |
| **Multi-Step Jobs** | Native support v·ªõi Job Context | C·∫ßn Spring Batch |
| **File Processing** | Built-in Excel/CSV support | C·∫ßn th√™m libraries |
| **SFTP Operations** | Built-in v·ªõi streaming | C·∫ßn Apache Commons VFS |
| **Webhook Triggers** | Built-in v·ªõi signature validation | C·∫ßn custom implementation |
| **Job Import/Export** | Built-in JSON format | Kh√¥ng c√≥ |
| **Observability** | Built-in (Prometheus + OTLP) | C·∫ßn th√™m dependencies |
| **Container Size** | <50MB | 200-500MB |

### L·ª£i √çch Cho Doanh Nghi·ªáp Vi·ªát Nam

1. **Chi Ph√≠ Th·∫•p**: Ti·∫øt ki·ªám 80% t√†i nguy√™n server
2. **Hi·ªáu NƒÉng Cao**: X·ª≠ l√Ω 10x nhi·ªÅu c√¥ng vi·ªác h∆°n
3. **D·ªÖ V·∫≠n H√†nh**: Dashboard tr·ª±c quan, logs r√µ r√†ng
4. **B·∫£o M·∫≠t**: Type-safe, kh√¥ng SQL injection, m√£ h√≥a bi·∫øn
5. **M·ªü R·ªông**: Horizontal scaling d·ªÖ d√†ng
6. **H·ªó Tr·ª£ Ti·∫øng Vi·ªát**: Documentation v√† UI ti·∫øng Vi·ªát

---

**Made with ‚ù§Ô∏è in Vietnam**
